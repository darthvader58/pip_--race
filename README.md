# pip --race (Pressure Is Privilege) 

A real-time Formula 1 race strategy system combining pit stop probability prediction and optimal pit window timing for Williams Racing. The system integrates two sophisticated backend models with a live frontend dashboard to provide actionable race strategy insights.

---

## System Overview

This system provides real-time strategic intelligence during F1 races by answering two critical questions:

1. **Which rival cars are likely to pit soon?** (Rival-Boxing Predictor)
2. **When should we call our driver to pit?** (Pit-Timer)

The architecture consists of:
- **Two specialized backend models** (QR-DQN classifier + Rust pit timer)
- **Bridge service** for WebSocket communication
- **React frontend** for live visualization
- **FastF1 data ingestion pipeline**

---

## Model 1: Rival-Boxing Predictor (QR-DQN)

### Architecture

**Type**: Quantile Regression Deep Q-Network (QR-DQN)  
**Framework**: PyTorch  
**Purpose**: Predict probability that any driver will pit within next 2-3 laps

```
Input (26 features) 
    ‚Üì
Linear(26 ‚Üí 256) + ReLU
    ‚Üì
Linear(256 ‚Üí 256) + ReLU
    ‚Üì
Linear(256 ‚Üí 2 √ó 101)  [2 actions √ó 101 quantiles]
    ‚Üì
Reshape ‚Üí [Batch, 2 Actions, 101 Quantiles]
    ‚Üì
Mean over quantiles ‚Üí Q(NO_PIT), Q(PIT)
    ‚Üì
Gap = Q(PIT) - Q(NO_PIT)
    ‚Üì
Platt Scaling: œÉ(coef √ó gap + intercept)
    ‚Üì
Output: P(box within 2 laps)
```

**Network Dimensions:**
- **Input**: 26 features (hazard + tactical state)
- **Hidden layers**: 2 √ó 256 neurons with ReLU activation
- **Output**: 2 actions √ó 101 quantile estimates
- **Parameters**: ~200K trainable weights

### Input Features (26 dimensions)

**Hazard Features (14)** ‚Äî tire degradation signals:
- `tire_age_laps`: Current tire age in laps
- `stint_no`: Which stint (1st, 2nd, 3rd...)
- `compound_SOFT`, `compound_MED`, `compound_HARD`, `compound_INTERMEDIATE`, `compound_WET`: One-hot tire type
- `last3_avg`: Average lap time over last 3 laps
- `last5_slope`: Linear regression slope of last 5 lap times (degradation rate)
- `last3_var`: Variance in last 3 lap times (consistency)
- `typical_stint_len`: Track-specific median stint length for this compound
- `age_vs_typical`: Difference from typical stint length
- `age_percentile`: Normalized age (0-1 scale relative to typical)
- `overshoot`: How many laps past typical stint length (clipped at 0)

**Tactical Features (12)** ‚Äî strategic environment:
- `cheap_stop_flag`: Is track under yellow/VSC/SC (cheap pit opportunity)?
- `cheap_prev1`, `cheap_prev2`: Cheap flags in previous 1-2 laps
- `non_green_runlen`: Consecutive laps under non-green conditions
- `pits_prev1`, `pits_prev2`: Number of grid-wide pits in previous 1-2 laps
- `tire_age_laps` (duplicated): Used twice in feature vector for emphasis
- `compound_*` (duplicated √ó 5): Tire type one-hot repeated

### Mathematical Formula

#### Quantile Huber Loss (Training Objective)

For each state-action pair (s, a), the model learns a distribution of Q-values via quantiles:

```
œÑ·µ¢ = (i + 0.5) / N_quantiles,  i ‚àà {0, 1, ..., 100}

u = TZ - ZŒ∏(s,a)    [TD error for each quantile]

œÅ·µè(u) = {  0.5 u¬≤                if |u| ‚â§ Œ∫
        {  Œ∫(|u| - 0.5Œ∫)         otherwise     [Huber loss]

‚Ñí_QR = ùîº[ Œ£·µ¢ |œÑ·µ¢ - ùüô(u < 0)| ¬∑ œÅ·µè(u·µ¢) ]
```

Where:
- `TZ = r + Œ≥¬≤ ¬∑ ZŒ∏'(s', argmax_a' QÃÑ(s',a'))` ‚Äî target quantiles (2-step bootstrapped)
- `ZŒ∏(s,a)` ‚Äî predicted quantiles for action a
- `Œ∫ = 1.0` ‚Äî Huber threshold
- `Œ≥ = 0.98` ‚Äî discount factor

#### Reward Shaping

```
r(s, a, outcome) = {
    +2.0 √ó boost     if a = PIT and actual_pit_within_2_laps = True
    -0.05            if a = PIT and actual_pit_within_2_laps = False
     0.0             if a = NO_PIT
}

boost = {  1.3   if cheap_stop_flag = 1  (yellow/VSC/SC)
        {  1.0   otherwise
```

**Rationale**: 
- Heavily reward correct pit predictions (+2.0 base, +2.6 during yellows)
- Small penalty for false alarms to encourage precision
- Zero reward for NO_PIT to focus learning on pit decisions

#### Probability Calibration (Platt Scaling)

After training, raw Q-gap scores are calibrated to probabilities:

```
score(s) = QÃÑ_PIT(s) - QÃÑ_NO_PIT(s)    [mean over 101 quantiles]

P(box | s) = œÉ(w ¬∑ score + b) = 1 / (1 + exp(-(w ¬∑ score + b)))
```

Where `(w, b)` are fitted via logistic regression on validation set to maximize F2 score (recall-biased).

#### 3-Lap Horizon (Heuristic Extension)

```
P(box within 3 laps | s_t) = 1 - (1 - p‚ÇÇ(t)) √ó (1 - p‚ÇÇ(t+1))
```

Where:
- `p‚ÇÇ(t)` = calibrated 2-lap probability at current state
- `p‚ÇÇ(t+1)` = calibrated 2-lap probability at next-lap features

### Output

**Primary**: `p2` ‚Äî Probability driver will pit within next 2 laps (0.0 to 1.0)  
**Secondary**: `p3` ‚Äî Probability driver will pit within next 3 laps (0.0 to 1.0)

**Example Output**:
```json
{
  "driver": "VER",
  "lap": 45,
  "p2": 0.87,
  "p3": 0.92,
  "t": 1730000000000
}
```

### Tech Stack

- **Training**: Python 3.11, PyTorch 2.x, FastF1 3.x
- **Inference Server**: Rust (Axum web framework, `tch-rs` for PyTorch JIT)
- **Model Format**: TorchScript (`qrdqn_torchscript.pt`)
- **Data**: Monaco 2023 race (primary training set)
- **Artifacts**: 
  - `artifacts/rl/qrdqn.pt` ‚Äî full checkpoint
  - `artifacts/rl/qrdqn_torchscript.pt` ‚Äî production model
  - `artifacts/rl/meta.json` ‚Äî feature list & hyperparameters
  - `artifacts/rl/calib_platt.json` ‚Äî Platt scaling coefficients

---

## ‚è±Ô∏è Model 2: Pit-Timer Backend

### Architecture

**Type**: Real-time physics-based state machine  
**Framework**: Rust (Tokio async runtime)  
**Purpose**: Compute optimal pit call timing based on track position and speed

```
Telemetry Stream (WebSocket)
    ‚Üì
{lap_distance_m, speed_kph, speed_profile}
    ‚Üì
Load Track Config (pit_entry_m, call_offset_m, buffer_s)
    ‚Üì
Compute: d_rem = max(0, (pit_entry_m - call_offset_m) - lap_distance_m)
    ‚Üì
Integrate: t_call = ‚à´[x_current to x_call] (1/v(x)) dx
    ‚Üì
Apply Buffer: t_safe = t_call - buffer_s
    ‚Üì
Status Logic:
  if t_safe < 0        ‚Üí LOCKED_OUT
  elif t_safe < 2s     ‚Üí RED (PIT NOW!)
  elif t_safe < 5s     ‚Üí AMBER (PREPARE)
  else                 ‚Üí GREEN (CLEAR TO PIT)
    ‚Üì
Broadcast {t_call, t_safe, status, lap_distance_m, speed_kph}
```

### Input

**Telemetry Packet** (JSON via WebSocket):
```json
{
  "lap_distance_m": 2450.5,
  "speed_kph": 187.3,
  "speed_profile": [
    {"x_m": 2400.0, "v_mps": 51.2},
    {"x_m": 2425.0, "v_mps": 52.1},
    {"x_m": 2450.0, "v_mps": 52.0}
  ]
}
```

**Track Configuration** (Monaco example):
```json
{
  "pit_entry_m": 2700.0,
  "call_offset_m": 180.0,
  "buffer_s": 0.8
}
```

### Mathematical Formula

#### Core Timing Calculation

```
x_current = lap_distance_m                    [current position on lap]
x_call = pit_entry_m - call_offset_m          [optimal call point]
d_rem = max(0, x_call - x_current)            [distance remaining to call point]
```

#### Time Integration (Trapezoidal Rule)

Instead of naive `t = d/v`, integrate over variable speed profile:

```
t_call = ‚à´[x_current to x_call] (1 / v(x)) dx

Discretized (trapezoidal):
t_call ‚âà Œ£·µ¢ (x·µ¢‚Çä‚ÇÅ - x·µ¢) ¬∑ 0.5 ¬∑ (1/v·µ¢ + 1/v·µ¢‚Çä‚ÇÅ)
```

Where:
- `v(x)` is interpolated from `speed_profile` samples
- Handles acceleration/deceleration zones more accurately
- Falls back to instantaneous speed if no profile available: `t_call = d_rem / v_inst`

#### Safety Buffer

```
t_safe = t_call - buffer_s
```

**buffer_s** = radio transmission delay + driver reaction time (typically 0.8-1.5s)

#### Status Thresholds

```
status = {
    "LOCKED_OUT"   if t_safe < 0      [too late, missed the window]
    "RED"          if 0 ‚â§ t_safe < 2  [critical: pit NOW!]
    "AMBER"        if 2 ‚â§ t_safe < 5  [prepare: get ready to pit]
    "GREEN"        if t_safe ‚â• 5      [clear: optimal window open]
}
```

### Output

**Real-time Broadcast** (JSON via WebSocket):
```json
{
  "t_call": 3.85,
  "t_safe": 3.05,
  "status": "AMBER",
  "lap_distance_m": 2450.5,
  "speed_kph": 187.3
}
```

- `t_call` ‚Äî seconds until optimal radio call point
- `t_safe` ‚Äî seconds until latest safe call (with buffer)
- `status` ‚Äî GREEN | AMBER | RED | LOCKED_OUT
- Telemetry echo for frontend display

### Tech Stack

- **Language**: Rust 2021 edition
- **Async Runtime**: Tokio 1.39
- **WebSocket**: `tokio-tungstenite` 0.23
- **Serialization**: `serde` + `serde_json`
- **Concurrency**: `broadcast` channel for fanout to multiple clients
- **Config**: JSON track profiles (`tracks/monaco.json`)

---

## üåê System Integration

### Data Flow

```
FastF1 Cache (Monaco 2023)
    ‚Üì
feeder_fastf1_cache.py  [computes 26 features per lap]
    ‚Üì
    ‚îú‚îÄ‚îÄ‚Üí HTTP POST: rt_predictor (Rust) ‚Üí {p2, p3}
    ‚îÇ        ‚Üì
    ‚îÇ    bridge-service (Node.js) ‚Üí WebSocket fanout
    ‚îÇ        ‚Üì
    ‚îî‚îÄ‚îÄ‚Üí Frontend: PitProbabilities component
    
Telemetry Stream (FastF1 simulated 5Hz)
    ‚Üì
telemetry_feed.py ‚Üí speed_profile_calculator
    ‚Üì
WebSocket: pit_timer_backend (Rust) ‚Üí {t_call, t_safe, status}
    ‚Üì
Frontend: BoxWindow component
```

### Bridge Service (Node.js)

**Purpose**: Decouple feeder ‚Üí predictor from frontend WebSocket clients

```javascript
// Receives from feeder via HTTP POST
app.post('/update', (req, res) => {
  const { driver, lap, p2, p3, t } = req.body;
  predictions.set(driver, { driver, lap, p2, p3, timestamp: t });
  broadcast({ type: 'UPDATE', prediction: { driver, lap, p2, p3 } });
});

// Broadcasts to all WebSocket clients
wss.on('connection', (ws) => {
  ws.send(JSON.stringify({ 
    type: 'FULL_STATE', 
    probabilities: Array.from(predictions.values()) 
  }));
});
```

**Why?** 
- Feeder runs at lap-rate (~80-100 seconds per update)
- Predictor is stateless HTTP service
- Frontend needs persistent WebSocket connection with immediate updates

### Frontend Components

**React SPA** with 3 pages:

1. **Live Race** (`/`) ‚Äî Williams car telemetry cards
2. **Strategy** (`/strategy`) ‚Äî Combined pit probabilities + box window timer
3. **About** (`/about`) ‚Äî Team information

**Key Hooks**:
- `useWebSocket(timerUrl)` ‚Äî connects to pit_timer_backend
- `usePitProbabilities(bridgeUrl)` ‚Äî connects to bridge-service
- `useRouter()` ‚Äî hash-based routing

---

## Performance Metrics

### Rival-Boxing Predictor (QR-DQN)

**Validation Set (Monaco 2023, last 20% of race)**:
- **AUC-ROC**: 0.87 (proxy reward labels)
- **Average Precision**: 0.82
- **Optimal Threshold**: 0.65 (F2-optimized)
- **Precision**: 0.71 @ 0.65 threshold
- **Recall**: 0.84 @ 0.65 threshold
- **F2 Score**: 0.81 (recall-weighted)

**Production Latency**:
- Inference: ~2-5ms per driver (CPU)
- End-to-end (feeder ‚Üí frontend): <50ms

### Pit-Timer Backend

**Timing Accuracy**:
- Integration error vs. naive `d/v`: ¬±0.1-0.3s improvement in variable-speed zones
- Status updates: 30ms frontend smoothing (countdown timer)

**Throughput**:
- Handles 5Hz telemetry stream per car
- Broadcast fanout: 10+ concurrent WebSocket clients
- Latency: <10ms per packet

---

## üöÄ Usage

### Training the QR-DQN Model

```bash
cd rival-boxing
python trainer/train_qrdqn.py \
  --races "2023:Monaco" \
  --epochs 20 \
  --batch_size 512 \
  --n_quantiles 101 \
  --hidden 256 \
  --oversample_pos 8 \
  --pos_reward 2.0 \
  --cheap_boost 1.3 \
  --target_recall 0.8
```

### Exporting to TorchScript

```bash
python scripts/export_torchscript_26.py \
  --ckpt artifacts/rl/qrdqn.pt \
  --meta artifacts/rl/meta.json \
  --out_ts artifacts/rl/qrdqn_torchscript.pt \
  --update_meta
```

### Running Inference Server

```bash
cd rival-boxing/rt_predictor
export MODEL_PATH=../artifacts/rl/qrdqn_torchscript.pt
export META_PATH=../artifacts/rl/meta.json
export PORT=8080
cargo run --release
```

### Starting Bridge Service

```bash
cd bridge-service
npm install
npm start  # Runs on port 8081
```

### Running Pit Timer Backend

```bash
cd pit_timer_backend
cargo run --release  # Runs on port 8765
```

### Streaming Telemetry

```bash
cd telemetry_feed
pip install -r requirements.txt
export BACKEND_URL=ws://localhost:8765
python telemetry_feed.py
```

### Feeding Predictions

```bash
cd rival-boxing/ingest
python feeder_fastf1_cache.py \
  --race "2023:Monaco" \
  --cache ../data/fastf1_cache \
  --url http://localhost:8080/ingest \
  --bridge http://localhost:8081/update \
  --meta ../artifacts/rl/meta.json \
  --sleep 0.1
```

### Running Frontend

```bash
cd frontend
npm install
npm run dev  # Vite dev server on http://localhost:5173
```

**Environment Variables** (`.env`):
```
VITE_PIT_TIMER_WS=ws://localhost:8765
VITE_PROBS_WS=ws://localhost:8081
```

---

## Project Structure

```
.
‚îú‚îÄ‚îÄ rival-boxing/
‚îÇ   ‚îú‚îÄ‚îÄ trainer/                 # QR-DQN training scripts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_qrdqn.py
‚îÇ   ‚îú‚îÄ‚îÄ rt_predictor/            # Rust inference server
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.rs          # Axum HTTP API
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.rs         # TorchScript loader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Cargo.toml
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ export_torchscript_26.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict_qrdqn.py           # Single-driver analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict_qrdqn_multidriver.py
‚îÇ   ‚îú‚îÄ‚îÄ ingest/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feeder_fastf1_cache.py     # FastF1 ‚Üí predictor pipeline
‚îÇ   ‚îî‚îÄ‚îÄ artifacts/
‚îÇ       ‚îú‚îÄ‚îÄ rl/                   # Model checkpoints
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ qrdqn.pt
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ qrdqn_torchscript.pt
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ meta.json
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ calib_platt.json
‚îÇ       ‚îî‚îÄ‚îÄ reports/              # Training metrics
‚îÇ
‚îú‚îÄ‚îÄ pit_timer_backend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.rs               # WebSocket server
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.rs              # Timing calculations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.rs             # Track config loader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tracks/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ monaco.json
‚îÇ   ‚îî‚îÄ‚îÄ Cargo.toml
‚îÇ
‚îú‚îÄ‚îÄ telemetry_feed/
‚îÇ   ‚îú‚îÄ‚îÄ telemetry_feed.py         # FastF1 ‚Üí pit_timer stream
‚îÇ   ‚îú‚îÄ‚îÄ speed_profile_calculator.py
‚îÇ   ‚îî‚îÄ‚îÄ test_speed_profile.py
‚îÇ
‚îú‚îÄ‚îÄ bridge-service/
‚îÇ   ‚îú‚îÄ‚îÄ server.js                 # Node.js WebSocket bridge
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îî‚îÄ‚îÄ frontend/
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
    ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useWebSocket.js       # Pit timer connection
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ usePitProbabilities.js # Bridge connection
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useRouter.js
    ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PitProbabilities.jsx  # Grid-wide pit probs
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BoxWindow.jsx         # Pit timer display
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CarCard.jsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TrackMap.jsx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Navigation.jsx
    ‚îÇ   ‚îú‚îÄ‚îÄ pages/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LiveRacePage.jsx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ StrategyPage.jsx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AboutPage.jsx
    ‚îÇ   ‚îî‚îÄ‚îÄ styles/
    ‚îÇ       ‚îî‚îÄ‚îÄ global.css
    ‚îú‚îÄ‚îÄ package.json
    ‚îî‚îÄ‚îÄ vite.config.js
```

---

## Key Design Decisions

### Why QR-DQN over Classification?

1. **Distributional RL**: Captures uncertainty in pit timing (quantiles vs. point estimate)
2. **Offline Learning**: Learns from historical race data without live interaction
3. **Reward Shaping**: Explicitly values cheap pit opportunities (yellows/VSC)
4. **Calibration**: Platt scaling maps Q-gaps to well-calibrated probabilities
5. **Performance Metric**: Less false negatives to gain an edge. Focus on Recall and AUC.

### Why Separate Pit Timer Backend?

1. **Decoupling**: Predictor (lap-rate updates) vs. timer (high-frequency position updates)
2. **Physics-based**: Integration over speed profiles for accuracy in acceleration zones
3. **Low Latency**: Rust async processing for <10ms broadcast cycles
4. **Track-specific**: Configurable per circuit (pit entry points, call offsets)

### Why Bridge Service?

1. **Protocol Translation**: HTTP (feeder) ‚Üí WebSocket (frontend)
2. **State Management**: Caches latest predictions for new client connections
3. **Fanout**: Broadcasts to multiple dashboard instances without predictor load

---
## Deployment
Vercel. Deployed on **__pitwit.vercel.app__** and **__pip-race.vercel.app__** . Backend server exists locally. Future work involves AWS/Convex Integration for Cloud based servers. 
---

## üõ†Ô∏è Dependencies

### Python (Training/Ingestion)
```
torch>=2.0
fastf1>=3.0
pandas>=2.0
numpy>=1.24
scikit-learn>=1.3
matplotlib>=3.7
requests>=2.31
```

### Rust (Inference/Timer)
```
axum = 0.7         # Web framework
tokio = 1.39       # Async runtime
tch = 0.15         # PyTorch bindings
serde = 1.0        # Serialization
tokio-tungstenite = 0.23  # WebSocket
```

### Node.js (Bridge)
```
express = 4.x
ws = 8.x           # WebSocket server
```

### Frontend
```
react = 18.x
vite = 5.x         # Build tool
```

---

## Future Enhancements

1. **Multi-Race Training**: Expand beyond Monaco to generalize across circuits
2. **Tire Compound Dynamics**: Integrate F1 tire model for degradation curves
3. **Weather Integration**: Add rain probability to tactical features
4. **Opponent Modeling**: Predict rival team strategies (undercut/overcut timing)
5. **DRS Detection**: Factor in DRS zones for pit loss calculations
6. **Real-Time Tuning**: Adaptive thresholds based on race phase (first stint vs. last 10 laps)
7. USE IT WITHIN ACTUAL **HPCs** (HIGH PERFORMANCE COMPUTING)

---

## License & Attribution

**Data Source**: FastF1 (https://github.com/theOehrly/Fast-F1)  
**Models**: Custom implementations for Williams Racing strategy optimization  
**Disclaimer**: This is a demonstration project for educational purposes. Not affiliated with Williams Racing or Formula 1.

---

## Contact

For questions about the models or architecture, please open an issue or refer to the inline code documentation.

**Happy Racing! üèÅ**
